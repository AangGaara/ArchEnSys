kali_ref_value   <- (kali_train_dataset$dist_gwh * kali_scale_dist_gwh) + kali_min_dist_gwh
kali_error_percent  <- ((kali_predict_value - kali_ref_value)/kali_ref_value) * 100
kali_results_denorm <- data.frame(kali_ref_value, kali_predict_value, kali_error_percent)
kali_results_denorm$region = "KALIMANTAN"
kali_results_denorm$year   = kali_dataset$year
setnames(kali_results_denorm, old = colnames(kali_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# SULAWESI ---------------------------------------------------------------
sula_dataset     <- his_dat[his_dat$region =="SULAWESI",]
# call min and max value for each column
sula_max_dist_gwh <- max(sula_dataset$dist_gwh)
sula_min_dist_gwh <- min(sula_dataset$dist_gwh)
sula_scale_dist_gwh <- sula_max_dist_gwh - sula_min_dist_gwh
sula_maxmindf  <- as.data.frame(sapply(sula_dataset[,c(2:11),], normalize))
# Create training & testing data set
sula_train_dataset   <- sula_maxmindf[1:(ceiling(nrow(sula_maxmindf) * percent_data)), ]
sula_test_dataset    <- sula_maxmindf[((ceiling(nrow(sula_maxmindf) * percent_data))+1):nrow(sula_maxmindf),]
# fit neural network
sula_nn <- neuralnet(dist_gwh ~ year + gdpr_billion_idr + gdpr_growth + population + kwh_dem_percap + intensity_biased,
data = sula_train_dataset,
hidden = c(ncol(sula_train_dataset), ncol(sula_train_dataset), ncol(sula_train_dataset)),
stepmax = 1e+5,
act.fct = "logistic",
linear.output = TRUE)
# plot(sula_nn, rep = "best",
#      arrow.length = 0.15,
#      col.entry  ="blue",
#      col.hidden ="red",
#      col.out    ="blue",
#      show.weights = TRUE,
#      information  = TRUE,
#      fontsize = 10)
#test the model to the training data
sula_predict = neuralnet::compute(sula_nn, sula_train_dataset)
sula_predict_value  <- (sula_predict$net.result * sula_scale_dist_gwh) + sula_min_dist_gwh
sula_ref_value   <- (sula_train_dataset$dist_gwh * sula_scale_dist_gwh) + sula_min_dist_gwh
sula_error_percent  <- ((sula_predict_value - sula_ref_value)/sula_ref_value) * 100
sula_results_denorm <- data.frame(sula_ref_value, sula_predict_value, sula_error_percent)
sula_results_denorm$region = "SULAWESI"
sula_results_denorm$year   = sula_dataset$year
setnames(sula_results_denorm, old = colnames(sula_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# MALUKU & PAPUA ---------------------------------------------------------------
malupa_dataset     <- his_dat[his_dat$region =="MALUKU_PAPUA",]
# call min and max value for each column
malupa_max_dist_gwh <- max(malupa_dataset$dist_gwh)
malupa_min_dist_gwh <- min(malupa_dataset$dist_gwh)
malupa_scale_dist_gwh <- malupa_max_dist_gwh - malupa_min_dist_gwh
malupa_maxmindf  <- as.data.frame(sapply(malupa_dataset[,c(2:11),], normalize))
# Create training & testing data set
malupa_train_dataset   <- malupa_maxmindf[1:(ceiling(nrow(malupa_maxmindf) * percent_data)), ]
malupa_test_dataset    <- malupa_maxmindf[((ceiling(nrow(malupa_maxmindf) * percent_data))+1):nrow(malupa_maxmindf),]
# fit neural network
malupa_nn <- neuralnet(dist_gwh ~ year + gdpr_billion_idr + gdpr_growth + population + kwh_dem_percap + intensity_biased,
data = malupa_train_dataset,
hidden = c(ncol(malupa_train_dataset), ncol(malupa_train_dataset), ncol(malupa_train_dataset)),
stepmax = 1e+5,
act.fct = "logistic",
linear.output = TRUE)
# plot(malupa_nn, rep = "best",
#      arrow.length = 0.15,
#      col.entry  ="blue",
#      col.hidden ="red",
#      col.out    ="blue",
#      show.weights = TRUE,
#      information  = TRUE,
#      fontsize = 10)
#test the model to the training data
malupa_predict = neuralnet::compute(malupa_nn, malupa_train_dataset)
malupa_predict_value  <- (malupa_predict$net.result * malupa_scale_dist_gwh) + malupa_min_dist_gwh
malupa_ref_value   <- (malupa_train_dataset$dist_gwh * malupa_scale_dist_gwh) + malupa_min_dist_gwh
malupa_error_percent  <- ((malupa_predict_value - malupa_ref_value)/malupa_ref_value) * 100
malupa_results_denorm <- data.frame(malupa_ref_value,
malupa_predict_value,
malupa_error_percent)
malupa_results_denorm$region = "MALUKU_PAPUA"
malupa_results_denorm$year   = malupa_dataset$year
setnames(malupa_results_denorm, old = colnames(malupa_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# bind all training results -----------------------------------------------
nn_train_results <- rbind(ind_results_denorm,
suma_results_denorm,
jawa_results_denorm,
bali_results_denorm,
kali_results_denorm,
sula_results_denorm,
malupa_results_denorm)
# ******************************************************************************
# prediction
# ******************************************************************************
source("demand_forecast_prediction_data_source.R")
# INDONESIA - Projection --------------------------------------------------
ind_proj_dataset     <- proj_dat[proj_dat$region =="INDONESIA",]
# call min and max value for each column
ind_proj_maxmindf  <- as.data.frame(sapply(ind_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
ind_proj_predict = neuralnet::compute(ind_nn, ind_proj_maxmindf)
ind_proj_predict_value  <- (ind_proj_predict$net.result * ind_scale_dist_gwh) + ind_max_dist_gwh
ind_proj_ref_value      <- ind_proj_dataset$electricity_demand_gwh
ind_proj_error_percent  <- ((ind_proj_predict_value - ind_proj_ref_value)/ind_proj_ref_value) * 100
ind_proj_results_denorm <- data.frame(ind_proj_ref_value, ind_proj_predict_value, ind_proj_error_percent)
ind_proj_results_denorm$region = "INDONESIA"
ind_proj_results_denorm$year   = ind_proj_dataset$year
setnames(ind_proj_results_denorm, old = colnames(ind_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# SUMATERA - Projection --------------------------------------------------
suma_proj_dataset     <- proj_dat[proj_dat$region =="SUMATERA",]
# call min and max value for each column
suma_proj_maxmindf  <- as.data.frame(sapply(suma_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
suma_proj_predict = neuralnet::compute(suma_nn, suma_proj_maxmindf)
suma_proj_predict_value  <- (suma_proj_predict$net.result * suma_scale_dist_gwh) + suma_max_dist_gwh
suma_proj_ref_value      <- suma_proj_dataset$electricity_demand_gwh
suma_proj_error_percent  <- ((suma_proj_predict_value - suma_proj_ref_value)/suma_proj_ref_value) * 100
suma_proj_results_denorm <- data.frame(suma_proj_ref_value, suma_proj_predict_value, suma_proj_error_percent)
suma_proj_results_denorm$region = "SUMATERA"
suma_proj_results_denorm$year   = suma_proj_dataset$year
setnames(suma_proj_results_denorm, old = colnames(suma_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# JAWA - Projection --------------------------------------------------
jawa_proj_dataset     <- proj_dat[proj_dat$region =="JAWA",]
# call min and max value for each column
jawa_proj_maxmindf  <- as.data.frame(sapply(jawa_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
jawa_proj_predict = neuralnet::compute(jawa_nn, jawa_proj_maxmindf)
jawa_proj_predict_value  <- (jawa_proj_predict$net.result * jawa_scale_dist_gwh) + jawa_max_dist_gwh
jawa_proj_ref_value      <- jawa_proj_dataset$electricity_demand_gwh
jawa_proj_error_percent  <- ((jawa_proj_predict_value - jawa_proj_ref_value)/jawa_proj_ref_value) * 100
jawa_proj_results_denorm <- data.frame(jawa_proj_ref_value, jawa_proj_predict_value, jawa_proj_error_percent)
jawa_proj_results_denorm$region = "JAWA"
jawa_proj_results_denorm$year   = jawa_proj_dataset$year
setnames(jawa_proj_results_denorm, old = colnames(jawa_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# BALI_NT - Projection --------------------------------------------------
bali_proj_dataset     <- proj_dat[proj_dat$region =="BALI_NT",]
# call min and max value for each column
bali_proj_maxmindf  <- as.data.frame(sapply(bali_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
bali_proj_predict = neuralnet::compute(bali_nn, bali_proj_maxmindf)
bali_proj_predict_value  <- (bali_proj_predict$net.result * bali_scale_dist_gwh) + bali_max_dist_gwh
bali_proj_ref_value      <- bali_proj_dataset$electricity_demand_gwh
bali_proj_error_percent  <- ((bali_proj_predict_value - bali_proj_ref_value)/bali_proj_ref_value) * 100
bali_proj_results_denorm <- data.frame(bali_proj_ref_value, bali_proj_predict_value, bali_proj_error_percent)
bali_proj_results_denorm$region = "BALI_NT"
bali_proj_results_denorm$year   = bali_proj_dataset$year
setnames(bali_proj_results_denorm, old = colnames(bali_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# KALIMANTAN - Projection --------------------------------------------------
kali_proj_dataset     <- proj_dat[proj_dat$region =="KALIMANTAN",]
# call min and max value for each column
kali_proj_maxmindf  <- as.data.frame(sapply(kali_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
kali_proj_predict = neuralnet::compute(kali_nn, kali_proj_maxmindf)
kali_proj_predict_value  <- (kali_proj_predict$net.result * kali_scale_dist_gwh) + kali_max_dist_gwh
kali_proj_ref_value      <- kali_proj_dataset$electricity_demand_gwh
kali_proj_error_percent  <- ((kali_proj_predict_value - kali_proj_ref_value)/kali_proj_ref_value) * 100
kali_proj_results_denorm <- data.frame(kali_proj_ref_value, kali_proj_predict_value, kali_proj_error_percent)
kali_proj_results_denorm$region = "KALIMANTAN"
kali_proj_results_denorm$year   = kali_proj_dataset$year
setnames(kali_proj_results_denorm, old = colnames(kali_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# SULAWESI - Projection --------------------------------------------------
sula_proj_dataset     <- proj_dat[proj_dat$region =="SULAWESI",]
# call min and max value for each column
sula_proj_maxmindf  <- as.data.frame(sapply(sula_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
sula_proj_predict = neuralnet::compute(sula_nn, sula_proj_maxmindf)
sula_proj_predict_value  <- (sula_proj_predict$net.result * sula_scale_dist_gwh) + sula_max_dist_gwh
sula_proj_ref_value      <- sula_proj_dataset$electricity_demand_gwh
sula_proj_error_percent  <- ((sula_proj_predict_value - sula_proj_ref_value)/sula_proj_ref_value) * 100
sula_proj_results_denorm <- data.frame(sula_proj_ref_value, sula_proj_predict_value, sula_proj_error_percent)
sula_proj_results_denorm$region = "SULAWESI"
sula_proj_results_denorm$year   = sula_proj_dataset$year
setnames(sula_proj_results_denorm, old = colnames(sula_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# MALUKU_PAPUA - Projection --------------------------------------------------
malupa_proj_dataset     <- proj_dat[proj_dat$region =="MALUKU_PAPUA",]
# call min and max value for each column
malupa_proj_maxmindf  <- as.data.frame(sapply(malupa_proj_dataset[,c(2:8),], normalize))
#test the model to the training data
malupa_proj_predict = neuralnet::compute(malupa_nn, malupa_proj_maxmindf)
malupa_proj_predict_value  <- (malupa_proj_predict$net.result * malupa_scale_dist_gwh) + malupa_max_dist_gwh
malupa_proj_ref_value      <- malupa_proj_dataset$electricity_demand_gwh
malupa_proj_error_percent  <- ((malupa_proj_predict_value - malupa_proj_ref_value)/malupa_proj_ref_value) * 100
malupa_proj_results_denorm <- data.frame(malupa_proj_ref_value, malupa_proj_predict_value, malupa_proj_error_percent)
malupa_proj_results_denorm$region = "MALUKU_PAPUA"
malupa_proj_results_denorm$year   = malupa_proj_dataset$year
setnames(malupa_proj_results_denorm, old = colnames(malupa_proj_results_denorm), new = c('ref_value',
'predict_value',
'error_percent',
'region',
'year'))
# bind all projection results -----------------------------------------------
nn_proj_results <- rbind(ind_proj_results_denorm,
suma_proj_results_denorm,
jawa_proj_results_denorm,
bali_proj_results_denorm,
kali_proj_results_denorm,
sula_proj_results_denorm,
malupa_proj_results_denorm)
# view(nn_proj_results)
# bind training + results
nn_results <- rbind(nn_train_results,
nn_proj_results)
# view(nn_results)
# bind all data
his_dat_df <- his_dat[c('region',
'year',
'gdpr_growth',
'intensity_biased',
'kwh_dem_percap',
'gdpr_billion_idr',
'population',
'gdpr_percap_thousand_idr')]
proj_dat_df <- proj_dat[c('region',
'year',
'gdpr_growth',
'intensity_biased',
'kwh_dem_percap',
'gdpr_billion_idr',
'population',
'gdpr_percap_thousand_idr')]
all_data  <- rbind(his_dat_df,
proj_dat_df)
# show data
view(his_dat)     # show historical data - training data
view(proj_dat)    # show ANN prediction results data
view(nn_results)  # show all results combined
view(all_data)    # show all historical and prediction data
#end of line
view(nn_results)  # show all results combined
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')]
View(demand_forecast_plot)
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh")
unique(nn_results$region)
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line() +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_plot)
library(readxl)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyverse)
library(networkD3)
library(scales)
options(scipen = 999, digits = 2) # avoid scientific notations
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line() +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_plot)
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line(aes(linetype = type, color = type)) +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_plot)
proj_dat <- subset(proj_dat, year!= "2019")
library(readxl)
library(tidyverse)
library(reshape2)
library(data.table)
setwd("C:/Users/Brajamusthi/OneDrive/Master of Energy Research/Github/ArchEnSys")
province_code <- read_excel("data_demand_forecast/glossary.xlsx",
sheet = "code")
# this script prepares prediction datasets
# dist_gwh = year + gdpr_billion_idr + gdpr_growth + population + gwh_cons_percap + intensity_biased,
# RUKN data read ______________________________________________________________________________
# read master data
sheet           <- excel_sheets("data_demand_forecast/forecast/rukn_proyeksi_kebutuhan_listrik.xlsx" )
rukn_projection = lapply(setNames(sheet, sheet),
function(x) read_excel("data_demand_forecast/forecast/rukn_proyeksi_kebutuhan_listrik.xlsx", range = "A2:L15", col_names = TRUE, sheet = x))
rukn_projection = bind_rows(rukn_projection, .id="Code")
rukn_projection$Code      <- as.numeric(sub("page ","", rukn_projection$Code, fixed = TRUE))
names(rukn_projection)[names(rukn_projection) == "URAIAN"] <- "old_var"
rukn_projection           <- subset(rukn_projection, old_var!= "ASUMSI & TARGET" & old_var!= "HASIL PROYEKSI")
rukn_projection$SATUAN    <- NULL
rukn_projection           <- rukn_projection %>%  mutate(old_var = str_remove_all(old_var, "\\s"))
#change variable names ***** does not work
# new_variables <- read_excel("data_demand_forecast/glossary.xlsx", sheet = "variables")
# projection_data <- merge(rukn_projection, unique(new_variables), all.x = TRUE, by = "old_var", sort = TRUE)
# projection_data$old_var <- NULL
# reshape the data
projection_data <- reshape2:: melt(rukn_projection, id.vars = c("Code","old_var"))
# assign name to each sheet
projection_data           <- merge(province_code, projection_data, by = "Code")
projection_data$Code      <- NULL
projection_data           <- na.omit(projection_data) #drop NA's
names(projection_data)[names(projection_data) == "variable"] <- "year"
#clean variable names
projection_data  <- projection_data %>%  mutate(old_var = str_remove_all(old_var, "\\s"))
new_variables    <- read_excel("data_demand_forecast/glossary.xlsx", range = "A1:B12", sheet = "variables")
new_variables    <- new_variables %>% mutate(old_var = str_remove_all(old_var,"\\s"))
projection_data  <- merge(projection_data, new_variables, by = 'old_var')
projection_data$old_var <- NULL
#change values to numerical
projection_data$value  <- sub(".","", projection_data$value, fixed = TRUE)
projection_data$value  <- sub(",",".", projection_data$value, fixed = TRUE)
projection_data$value  <- sub("(","-", projection_data$value, fixed = TRUE)
projection_data$value  <- sub(")","", projection_data$value, fixed = TRUE)
projection_data$value  <- as.numeric(projection_data$value)
projection_data$year   <- as.numeric(projection_data$year) + 2018 #set year to numeric
# pivot to wider variable
# https://seananderson.ca/2013/10/19/reshape/
projection_data_source <- reshape2:: dcast(projection_data,
Province + year ~ new_var,
value.var = "value",
fun.aggregate =  mean,
na.rm = TRUE)
# remove unneeded data
projection_data_source[,c('inflation',
'add_capacity_cum_gw',
'add_capacity_gw',
'electrification_ratio',
'total_capacity_gw')] <- NULL
# Read historical data ----------------------------------------------------
# read data from historical_data_source
# to take data from last year of the historical, in this case: 2019 data
source("demand_forecast_historical_data_source.R")
first_year = 2019
# will be calculated based on government targets
# please check report chapter 2, in Indonesia's energy policy section
# for long term the Energy intensity growth will be at -1% per year
intensity_growth = -1
#read 2019 data
gdpr_billion_idr_2019 <- historical_data_source[historical_data_source$year == first_year, c('Province',
'year',
'gdpr_billion_idr')]
population_2019       <- historical_data_source[historical_data_source$year == first_year, c('Province',
'year',
'population')]
intensity_2019        <- historical_data_source[historical_data_source$year == first_year, c('Province',
'year',
'intensity_biased')]
#input 2019 data to projection data source
projection_data_source <- merge(projection_data_source, gdpr_billion_idr_2019, by = c("Province","year"), all.x = TRUE, sort = FALSE)
projection_data_source <- merge(projection_data_source, population_2019, by = c("Province","year"), all.x = TRUE, sort = FALSE)
projection_data_source <- merge(projection_data_source, intensity_2019, by = c("Province","year"), all.x = TRUE, sort = FALSE)
# Populate data with calculated values ------------------------------------
aprojection_data_source <- projection_data_source # for trial and error
for (i in unique(aprojection_data_source$Province)){
for (j in aprojection_data_source$year[aprojection_data_source$year > first_year]){
current_location  = aprojection_data_source$Province == i & aprojection_data_source$year == j
previous_location = aprojection_data_source$Province == i & aprojection_data_source$year == j-1
# GDRP in billion IDR
aprojection_data_source$gdpr_billion_idr[current_location] <-
aprojection_data_source$gdpr_billion_idr[previous_location] * (1+(aprojection_data_source$gdpr_growth[current_location]/100))
# population
aprojection_data_source$population[current_location] <-
aprojection_data_source$population[previous_location] * (1+(aprojection_data_source$population_growth[current_location]/100))
# energy intensity
aprojection_data_source$intensity_biased[current_location] <-
aprojection_data_source$intensity_biased[previous_location] * (1+(intensity_growth/100))
}
}
# Create projection dataset -----------------------------------------------
colnames(aprojection_data_source)
projection_dataset <- aprojection_data_source[c('Province',
'year',
'electricity_demand_gwh',
'gdpr_billion_idr',
'gdpr_growth',
'population',
'kwh_dem_percap',
'intensity_biased',
'electricity_demand_gwh')]
# assign region
province_region <- read_excel("data_demand_forecast/glossary.xlsx", sheet = "region")
projection_dataset <- merge(province_region, projection_dataset, all.x = TRUE, by = "Province", sort = TRUE)
#summarise
proj_dat <- projection_dataset
proj_dat$Province <- NULL
proj_dat_mean <- proj_dat %>%
group_by(region, year) %>%
summarise(across(c(gdpr_growth,
intensity_biased,
kwh_dem_percap),mean))
proj_dat_sum <- proj_dat %>%
group_by(region, year) %>%
summarise(across(c(electricity_demand_gwh,
gdpr_billion_idr,
population),sum))
proj_dat <- merge(proj_dat_mean, proj_dat_sum, by = c("region", "year"), sort = FALSE)
proj_dat$gdpr_percap_thousand_idr <- 1000000 * proj_dat$gdpr_billion_idr / proj_dat$population
proj_dat <- subset(proj_dat, year!= "2019")
View(proj_dat)
library(readxl)
library(dplyr)
library(ggplot2)
library(plotly)
library(tidyverse)
library(networkD3)
library(scales)
setwd("C:/Users/Brajamusthi/OneDrive/Master of Energy Research/Github/ArchEnSys")
options(scipen = 999, digits = 2) # avoid scientific notations
# ******************************************************************************
# Demand forecasting visualizations
# ******************************************************************************
source("demand_forecast_neural_network_all.R")
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line(aes(linetype = type, color = type)) +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_plot)
const_nrn_plot <-
constraints[c('year', 'nrn_target', 'nrn_act')] %>%
pivot_longer(cols=2:3, names_to = "type", values_to = "share") %>%
ggplot(aes(year, share, group = type)) +
geom_line(aes(linetype = type, color = type)) +
labs(title = "Target vs Actual Share from Renewable Generation",
x = "year",
y = "Share (%)")
ggplotly(const_nrn_plot)
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
subset(sup_gwh, region != 'INDONESIA') %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line(aes(linetype = type, color = type)) +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
demand_forecast_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
subset(region != 'INDONESIA') %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line(aes(linetype = type, color = type)) +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_plot)
demand_forecast_ind_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
subset(region == 'INDONESIA') %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line(aes(linetype = type, color = type)) +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_ind_plot)
demand_forecast_regional_plot <-
nn_results[c('region','year','ref_value','predict_value')] %>%
subset(region != 'INDONESIA') %>%
pivot_longer(cols = 3:4, names_to = "type", values_to = "GWh") %>%
ggplot(aes(year, GWh, group = type)) +
geom_line(aes(linetype = type, color = type)) +
facet_grid(cols = vars(region)) +
labs(title = "Electricity Demand Projection, RUKN vs ANN, by region",
x = "year",
y = "GWh")
ggplotly(demand_forecast_regional_plot)
setwd(getSrcDirectory()[1])
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) #set working directory to this script's location
province_code <- read_excel("data_demand_forecast/glossary.xlsx",
sheet = "code")
